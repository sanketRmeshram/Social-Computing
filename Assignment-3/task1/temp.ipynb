{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Name : Sanket Meshram\n",
    "Roll No. : 17CS30030\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def remove_punctuation_and_lower(a):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    a = a.lower()\n",
    "    for x in punctuations:\n",
    "        a = a.replace(x, \"\")\n",
    "    return a\n",
    "\n",
    "\n",
    "def read_train_and_preprocess():\n",
    "    File = open(\"../data/train.tsv\", \"r\")\n",
    "    data = {\"id\": [], \"text\": [],  \"hateful\": []}\n",
    "    File.readline()\n",
    "    while True:\n",
    "        line = File.readline()\n",
    "        if len(line) == 0:\n",
    "            break\n",
    "        line = remove_punctuation_and_lower(line)\n",
    "        line = line.split()\n",
    "        data[\"id\"].append(line[0])\n",
    "        data[\"hateful\"].append(int(line[-1]))\n",
    "        data[\"text\"].append(' '.join(line[1:-1]))\n",
    "\n",
    "\n",
    "    return data[\"id\"], data[\"text\"], data[\"hateful\"]\n",
    "\n",
    "\n",
    "def read_test_and_preprocess():\n",
    "    File = open(\"../data/test.tsv\", \"r\")\n",
    "    data = {\"id\": [], \"text\": []}\n",
    "    File.readline()\n",
    "    while True:\n",
    "        line = File.readline()\n",
    "        if len(line) == 0:\n",
    "            break\n",
    "        line = remove_punctuation_and_lower(line)\n",
    "        line = line.split()\n",
    "        data[\"id\"].append(line[0])\n",
    "        data[\"text\"].append(' '.join(line[1:]))\n",
    "\n",
    "\n",
    "    return data[\"id\"], data[\"text\"]\n",
    "\n",
    "def get_TfIdf(x):\n",
    "    vectorizer = TfidfVectorizer(max_df=.8, min_df=.05)\n",
    "    vectors = vectorizer.fit_transform(x)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "    df = pd.DataFrame(denselist, columns=feature_names)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_to_TfIdf(train,test) :\n",
    "    temp = train.copy() + test.copy()\n",
    "    len_train = len(train)\n",
    "    print(temp[:10])\n",
    "    now = get_TfIdf(temp)\n",
    "    return now.iloc[:len_train],now.iloc[len_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "id_train, x_train, y_train = read_train_and_preprocess()\n",
    "id_test, x_test = read_test_and_preprocess()\n",
    "\n",
    "len_train = len(x_train)\n",
    "len_test = len(x_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1605279855646",
   "display_name": "Python 3.7.7 64-bit ('data_science': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}